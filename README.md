# RAG Factory ğŸ­

**A production-ready, open-source platform for building and managing multiple RAG (Retrieval-Augmented Generation) systems â€” 100% local, no vendor lock-in.**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![React 19](https://img.shields.io/badge/React-19-61dafb.svg)](https://react.dev/)

> **âš¡ Quick Start**: `git clone` â†’ `docker-compose up -d` â†’ Open [http://localhost:3000](http://localhost:3000) â†’ Start building RAG systems in minutes!

---

## ğŸ¯ What is RAG Factory?

RAG Factory is a **complete platform** for developers, researchers, and teams who need to build production-grade RAG systems **without the complexity**. No expensive API costs, no cloud dependencies, no vendor lock-in.

### Why RAG Factory?

- **ğŸ  100% Local**: Everything runs in Docker â€” your data never leaves your infrastructure
- **ğŸ¨ Beautiful UI**: Modern React dashboard for managing projects, sources, and jobs
- **ğŸ”Œ 10+ Connectors**: SPARQL, REST APIs, GitHub, Google Drive, Notion, RSS, Web Scraper, and more
- **ğŸ“… Smart Scheduling**: Automate syncs with cron expressions, intervals, or presets
- **ğŸ¤– Full RAG Pipeline**: Semantic search + LLM generation (using local Ollama models)
- **ğŸ“Š Real-Time Monitoring**: Live job progress, analytics dashboard, and insights
- **ğŸ—„ï¸ Your Database**: Vectors stored in *your* PostgreSQL â€” you control everything
- **ğŸŒ Multi-Jurisdiction**: Built-in country/region tagging for global applications
- **âš¡ Production-Ready**: Deduplication, retry logic, rate limiting, error handling

## ğŸ—ï¸ Architecture

```ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     React Frontend (Port 3000)              â”‚
â”‚  â€¢ Project Management  â€¢ Source Configuration               â”‚
â”‚  â€¢ Job Monitoring      â€¢ RAG Search & Query UI              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FastAPI Backend (Port 8000)               â”‚
â”‚  â€¢ REST API        â€¢ Health Checks    â€¢ Scheduling          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                       â”‚
          â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis (Queue)   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚   RQ Workers        â”‚
â”‚  â€¢ Job Queue     â”‚                    â”‚   â€¢ Fetch docs      â”‚
â”‚  â€¢ Scheduling    â”‚                    â”‚   â€¢ Embed & Store   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                                        â”‚             â”‚
          â–¼                                        â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Internal DB     â”‚                    â”‚   Ollama    â”‚  â”‚  Your DB    â”‚
â”‚  rag_factory_db  â”‚                    â”‚  â€¢ Embed    â”‚  â”‚  â€¢ Vectors  â”‚
â”‚  â€¢ Projects      â”‚                    â”‚  â€¢ LLM Gen  â”‚  â”‚  â€¢ Metadata â”‚
â”‚  â€¢ Jobs tracking â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â€¢ Doc hashes    â”‚                    (Port 11434)     (Your config)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
(Port 5433)
```

**ğŸ”‘ Key Concepts:**

- **Two-Database System**: Internal DB tracks everything; your DB stores only vectors
- **Async Processing**: Redis Queue + RQ Workers handle long-running ingestion jobs
- **Local LLM**: Ollama provides embeddings (jina/jina-embeddings-v2-base-es bilingual ES/EN) and generation (Gemma 3)
- **No Vendor Lock-In**: Your vectors live in your PostgreSQL database

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- 8GB RAM minimum (16GB recommended for Ollama models)
- PostgreSQL database with pgvector extension (for production use)

### Option 1: One-Command Setup (Recommended)

```bash
# Clone, start, and open dashboard
git clone https://github.com/felixrivasuxdesigner/rag-factory.git
cd rag-factory
./setup.sh
```

This script will:
1. Start all Docker services
2. Wait for services to be healthy
3. Download Ollama models (embeddings + LLM)
4. Open the dashboard at http://localhost:3000

### Option 2: Manual Setup

```bash
git clone https://github.com/felixrivasuxdesigner/rag-factory.git
cd rag-factory

# Start all services
docker-compose -f docker/docker-compose.yml up -d

# Wait for services (check health)
curl http://localhost:8000/health

# Download Ollama models (required for embeddings)
docker exec ollama ollama pull jina/jina-embeddings-v2-base-es
docker exec ollama ollama pull gemma3:1b-it-qat

# Open the dashboard
open http://localhost:3000  # macOS
# or visit http://localhost:3000 in your browser
```

### ğŸŒ Access Points

- **Dashboard**: <http://localhost:3000> (React UI)
- **API**: <http://localhost:8000>
- **API Docs**: <http://localhost:8000/docs> (Swagger)
- **PostgreSQL**: `localhost:5433`
- **Redis**: `localhost:6380`
- **Ollama**: <http://localhost:11434>

### âš¡ Optional: Enable Google AI Cloud (Recommended)

Get **15x faster** RAG responses with Google AI's free cloud LLMs:

```bash
# 1. Get free API key from https://aistudio.google.com/apikey
# 2. Configure environment
cd docker
echo "GOOGLE_AI_API_KEY=your-api-key-here" > .env

# 3. Restart API
docker-compose restart api

# 4. In the UI, select "Google AI Cloud" from the LLM Provider dropdown
```

**Performance:**
- Google AI Cloud: ~8 seconds âš¡
- Ollama Local: ~40-120 seconds ğŸŒ

**Cost:** FREE (1,500 queries/day)

### 2. Create Your First RAG Project

```bash
curl -X POST "http://localhost:8000/projects" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "My Legal Assistant",
    "description": "RAG for legal documents",
    "target_db_host": "your-db-host",
    "target_db_port": 5432,
    "target_db_name": "your_database",
    "target_db_user": "your_user",
    "target_db_password": "your_password",
    "target_table_name": "legal_vectors",
    "embedding_model": "jina/jina-embeddings-v2-base-es",
    "embedding_dimension": 768
  }'
```

### 3. Add a Data Source

```bash
curl -X POST "http://localhost:8000/sources" \
  -H "Content-Type: application/json" \
  -d '{
    "project_id": 1,
    "name": "Chile Legal Documents",
    "source_type": "sparql",
    "country_code": "CL",
    "tags": {"language": "es"},
    "config": {
      "endpoint": "https://datos.bcn.cl/es/endpoint-sparql",
      "limit": 100
    }
  }'
```

### 4. Trigger Ingestion

```bash
curl -X POST "http://localhost:8000/jobs" \
  -H "Content-Type: application/json" \
  -d '{"project_id": 1, "job_type": "full_sync"}'
```

### 5. Monitor Progress

```bash
# Check job status
curl "http://localhost:8000/jobs/1"

# Check project stats
curl "http://localhost:8000/projects/1/stats"
```

## ğŸ“š Documentation

- **[API Usage Guide](API_USAGE.md)** - Complete API reference with examples
- **[CLAUDE.md](CLAUDE.md)** - Technical documentation for developers
- **[Interactive API Docs](http://localhost:8000/docs)** - Swagger UI (when running)

## ğŸŒ Multi-Country Example

Perfect for applications that need to handle documents from different jurisdictions:

```bash
# Source 1: Chile
curl -X POST "http://localhost:8000/sources" -H "Content-Type: application/json" -d '{
  "project_id": 1,
  "name": "Chile BCN",
  "source_type": "sparql",
  "country_code": "CL",
  "tags": {"language": "es", "jurisdiction": "national"},
  "config": {"endpoint": "https://datos.bcn.cl/es/endpoint-sparql"}
}'

# Source 2: USA
curl -X POST "http://localhost:8000/sources" -H "Content-Type: application/json" -d '{
  "project_id": 1,
  "name": "USA Federal",
  "source_type": "rest_api",
  "country_code": "US",
  "tags": {"language": "en", "jurisdiction": "federal"},
  "config": {"endpoint": "https://api.congress.gov/..."}
}'
```

Then query with country filtering:

```python
# Search only Chile documents
results = writer.similarity_search(
    query_embedding,
    country_code='CL',
    limit=10
)
```

## ğŸ§ª Testing

Run the automated end-to-end test:

```bash
python3 test_api.py
```

This tests:
- âœ… Health check
- âœ… Project creation
- âœ… Database connection
- âœ… Data source creation
- âœ… Job enqueueing
- âœ… Job progress monitoring
- âœ… Statistics retrieval

## ğŸ› ï¸ Tech Stack

- **Backend**: Python 3.11, FastAPI
- **Job Queue**: Redis + RQ (Redis Queue)
- **Database**: PostgreSQL + pgvector
- **Embeddings**: Ollama (jina/jina-embeddings-v2-base-es, 768 dimensions, bilingual ES/EN)
- **LLM Providers**:
  - **Google AI Cloud** (default) - gemini-flash-lite, gemma-3-4b, gemma-3-12b (free 1,500/day)
  - **Ollama Local** - gemma3:1b, gemma3:4b (optional, privacy-focused)
- **Frontend**: React 19 + TypeScript + Vite
- **Containerization**: Docker Compose

## âœ¨ Features

### ğŸ¯ Core Features (v0.8 - Production Ready)

**Backend & API**
- âœ… Multi-project RAG management
- âœ… 10+ data source connectors (see below)
- âœ… REST API with OpenAPI/Swagger docs
- âœ… Async job processing (Redis + RQ)
- âœ… Hash-based deduplication (SHA-256)
- âœ… Smart chunking (adaptive based on doc size)
- âœ… Rate limiting & retry logic
- âœ… Incremental sync support

**Frontend Dashboard**
- âœ… Modern React 19 + TypeScript UI
- âœ… Project & source management (CRUD)
- âœ… Real-time job monitoring with progress bars
- âœ… Analytics dashboard with charts
- âœ… RAG search & query interface
- âœ… Scheduling UI (presets + custom)
- âœ… 15+ pre-configured connector examples

**RAG Pipeline**
- âœ… Semantic search (cosine similarity)
- âœ… Full RAG queries (search + LLM generation)
- âœ… Local embeddings (Ollama jina/jina-embeddings-v2-base-es, 768d, bilingual ES/EN)
- âœ… **Dual LLM Support**: Google AI Cloud (fast, 8s) or Ollama Local (private, 40s+)
- âœ… **UI LLM Selector**: Switch providers & adjust response length in-app
- âœ… **Auto Language Detection**: Spanish/English bilingual support
- âœ… Country/region filtering
- âœ… Metadata-rich results

**Scheduling & Automation**
- âœ… APScheduler integration
- âœ… Cron expressions support
- âœ… Interval-based schedules (30m, 1h, 6h, daily, weekly)
- âœ… Manual trigger ("Sync Now")
- âœ… Pause/resume schedules
- âœ… Auto-load schedules on restart

### ğŸ”Œ Available Connectors

**Public (Generic)**
1. âœ… **SPARQL** - Any SPARQL endpoint (legal databases, knowledge graphs)
2. âœ… **REST API** - Generic JSON API connector
3. âœ… **File Upload** - PDF, DOCX, TXT, MD, JSON, CSV
4. âœ… **Web Scraper** - BeautifulSoup4 with CSS selectors
5. âœ… **RSS/Atom** - Blogs, news feeds, podcasts
6. âœ… **GitHub** - README, issues, PRs, code files
7. âœ… **Google Drive** - Docs, Sheets, PDFs (OAuth2)
8. âœ… **Notion** - Pages, databases (Integration Token)

**Example (Pre-configured)**
9. âœ… **Chile BCN** - Chilean legal norms (SPARQL)
10. âœ… **US Congress** - Federal bills (Congress.gov API)

### ğŸš§ Roadmap (See [ROADMAP.md](ROADMAP.md))

**Next (Phase 6+)**
- [ ] WebSocket for real-time updates
- [ ] Multi-tenancy & authentication
- [ ] Re-ranking for better search quality
- [ ] Kubernetes deployment configs
- [ ] Multi-modal support (images, audio)
- [ ] Query analytics dashboard

## ğŸ”§ Development

```bash
# Backend development
cd backend
pip install -r requirements.txt
uvicorn api.main:app --reload

# Run RQ worker locally
rq worker --url redis://localhost:6379/0 rag-tasks

# Run tests
python -m core.schema  # Test schema
python -m services.embedding_service  # Test embeddings
python -m services.vector_db_writer  # Test vector DB
```

See [CLAUDE.md](CLAUDE.md) for detailed development instructions.

## ğŸ“ Environment Variables

See `docker-compose.yml` for configuration options:

- `DATABASE_URL` - Internal database connection
- `REDIS_URL` - Redis connection for job queue
- `OLLAMA_HOST` - Ollama service hostname
- `GOOGLE_AI_API_KEY` - (Optional) Google AI API key for cloud LLM providers

**To enable Google AI Cloud:**
```bash
cd docker
echo "GOOGLE_AI_API_KEY=your-key-here" > .env
docker-compose restart api
```

## ğŸ¤ Contributing

We â¤ï¸ contributions! RAG Factory was built with [Claude Code](https://claude.com/claude-code) and is designed to be community-driven.

### Ways to Contribute

- ğŸ› **Report bugs** - [Open an issue](https://github.com/felixrivasuxdesigner/vector-doc-ingestion/issues/new?template=bug_report.md)
- ğŸ’¡ **Suggest features** - [Request a feature](https://github.com/felixrivasuxdesigner/vector-doc-ingestion/issues/new?template=feature_request.md)
- ğŸ”Œ **Build connectors** - Add support for new data sources ([Guide](CONTRIBUTING.md#creating-a-new-connector))
- ğŸ“ **Improve docs** - Fix typos, add examples, write tutorials
- ğŸ§ª **Write tests** - Help us reach 100% coverage
- ğŸ¨ **Enhance UI** - Improve the frontend experience

### Quick Start for Contributors

```bash
# Fork the repo, then:
git clone https://github.com/YOUR_USERNAME/vector-doc-ingestion.git
cd vector-doc-ingestion

# Backend development
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn api.main:app --reload

# Frontend development (in another terminal)
cd frontend
npm install
npm run dev
```

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

### Good First Issues

Looking for easy tasks to get started? Check out issues labeled [`good-first-issue`](https://github.com/felixrivasuxdesigner/vector-doc-ingestion/labels/good-first-issue):

- Add new connector for popular APIs
- Improve error messages
- Write documentation
- Add unit tests

## ğŸ“„ License

[MIT License](LICENSE) - Free to use, modify, and distribute.

## ğŸ™ Acknowledgments

- **Built with** [Claude Code](https://claude.com/claude-code) - AI-powered development assistant
- **Embeddings & LLM** [Ollama](https://ollama.ai/) - Local AI models (jina/jina-embeddings-v2-base-es bilingual, Gemma 3)
- **Vector Search** [pgvector](https://github.com/pgvector/pgvector) - PostgreSQL extension for similarity search
- **Job Queue** [RQ](https://python-rq.org/) - Redis Queue for async processing
- **Frontend** [React 19](https://react.dev/) + [Vite](https://vitejs.dev/) - Modern web stack
- **Example Data** Chile's [BCN Open Data](https://datos.bcn.cl/) (SPARQL endpoint)

## ğŸ“ Support & Community

- ğŸ“– **Documentation**: [API Usage Guide](API_USAGE.md) | [Architecture](CLAUDE.md) | [Roadmap](ROADMAP.md)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/felixrivasuxdesigner/vector-doc-ingestion/discussions)
- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/felixrivasuxdesigner/vector-doc-ingestion/issues)
- ğŸ“§ **Email**: felix.rivas.ux@gmail.com
- ğŸŒŸ **Star us on GitHub** if you find this useful!

## ğŸš€ What's Next?

1. **Try it out**: Run `./setup.sh` and explore the dashboard
2. **Read the docs**: Check out [API_USAGE.md](API_USAGE.md) for examples
3. **Build a connector**: Follow the [Connector Guide](CONTRIBUTING.md#creating-a-new-connector)
4. **Join the community**: Share your use case in [Discussions](https://github.com/felixrivasuxdesigner/vector-doc-ingestion/discussions)

## ğŸ’¼ Use Cases

RAG Factory is perfect for:

- ğŸ“š **Research & Academia** - Index papers, books, and research materials
- âš–ï¸ **Legal Tech** - Build legal document search systems
- ğŸ¢ **Enterprise Knowledge Base** - Internal docs, wikis, and resources
- ğŸ¥ **Healthcare** - Medical literature and patient resources
- ğŸŒ **Multi-lingual Apps** - Handle documents from different countries/languages
- ğŸ“ **Education** - Course materials and learning resources

---

<div align="center">

**â­ Star us on GitHub â€¢ ğŸ”Œ Contribute a connector â€¢ ğŸ“£ Share your RAG Factory project!**

Built with â¤ï¸ by the RAG Factory community

</div>
